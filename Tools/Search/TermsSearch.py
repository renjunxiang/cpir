"""
æœ¯è¯­æœç´¢

ä¿é™©æœ¯è¯­å®šä¹‰æŸ¥è¯¢
æ¶ˆä¿æœ¯è¯­å®šä¹‰æŸ¥è¯¢
"""

import json
from langchain_core.tools import tool
from langchain_core.runnables.config import RunnableConfig
from langgraph.runtime import get_runtime
from pydantic import BaseModel, Field
from Config.LLM_Client import llm, lock

with open("Tools/Search/insurance_terms.json", "r", encoding="utf-8") as f:
    insurance_terms = json.load(f)


class InsuranceSearchInput(BaseModel):
    """ä¿é™©æœ¯è¯­æŸ¥è¯¢çš„è¾“å…¥"""

    terms: list = Field(description="ä¿é™©æœ¯è¯­åˆ—è¡¨", default=[])


@tool(
    "ä¿é™©æœ¯è¯­æŸ¥è¯¢",
    description="è¾“å…¥ä¿é™©æœ¯è¯­åˆ—è¡¨ï¼Œè¾“å‡ºæ¯ä¸ªæœ¯è¯­çš„å®šä¹‰ã€‚",
    args_schema=InsuranceSearchInput,
)
def insurance_terms_search(terms: list, context: RunnableConfig) -> str:
    """
    è¾“å…¥ä¿é™©æœ¯è¯­åˆ—è¡¨ï¼Œè¾“å‡ºæ¯ä¸ªæœ¯è¯­çš„å®šä¹‰ã€‚
    """

    print(f"\nğŸ”æ£€ç´¢å·¥å…·=ä¿é™©æœ¯è¯­æŸ¥è¯¢")

    result = ""
    words = []
    with lock:
        # æ£€ç´¢å·¥å…·è°ƒç”¨ä¸­è¯†åˆ«åˆ°çš„ä¿é™©æœ¯è¯­
        # print("\nä»ä»»åŠ¡æŒ‡ä»¤ä¸­æ£€ç´¢æœ¯è¯­")
        for term in terms:
            if term in insurance_terms:
                one_term = f"{term}ï¼š{insurance_terms[term]}ã€‚"
                print(one_term)
                result += one_term
            else:
                words.append(term)
                # print(f"{term}ï¼šæœªæ‰¾åˆ°å®šä¹‰")

        # æ£€ç´¢å¾…å®¡æ ¸æ–‡æ¡£æ˜¯å¦å­˜åœ¨å…³é”®è¯
        # print("\nä»æ–‡æ¡£ä¸­æ£€ç´¢æœ¯è¯­")
        document = get_runtime(context).context.get("document", "")
        if document != "":
            for term in insurance_terms:
                if term in document and term not in result:
                    one_term = f"{term}ï¼š{insurance_terms[term]}ã€‚"
                    print(one_term)
                    result += one_term

        # ä»LLMä¸­è·å–æœ¯è¯­å®šä¹‰
        print("\nçŸ¥è¯†åº“æœªæŸ¥åˆ°çš„æœ¯è¯­ï¼ŒLLMè‡ªå·±çš„å®šä¹‰å¦‚ä¸‹ï¼š")
        prompt = f"""
        è¯·æ ¹æ®ä½ è‡ªå·±çš„ç†è§£ï¼Œç»™å‡ºè¿™äº›æœ¯è¯­çš„å®šä¹‰ï¼Œè¾“å‡ºå½¢å¼ä¸ºï¼šæœ¯è¯­1ï¼šæœ¯è¯­1çš„å®šä¹‰ã€‚æœ¯è¯­2ï¼šæœ¯è¯­2çš„å®šä¹‰...
        æœ¯è¯­æ¸…å•ä¸ºï¼š{words}
        """
        for chunk in llm.stream(prompt):
            print(chunk.content, end="", flush=True)
            result += chunk.content

    return result


with open("Tools/Search/consumer_protection_terms.json", "r", encoding="utf-8") as f:
    consumer_protection_terms = json.load(f)


class ConsumerProtectionSearchInput(BaseModel):
    """æ¶ˆä¿æœ¯è¯­æŸ¥è¯¢çš„è¾“å…¥"""

    terms: list = Field(description="æ¶ˆä¿æœ¯è¯­åˆ—è¡¨", default=[])


@tool(
    "æ¶ˆä¿æœ¯è¯­æŸ¥è¯¢",
    description="è¾“å…¥æ¶ˆä¿æœ¯è¯­åˆ—è¡¨ï¼Œè¾“å‡ºæ¯ä¸ªæœ¯è¯­çš„å®šä¹‰ã€‚",
    args_schema=ConsumerProtectionSearchInput,
)
def consumer_protection_terms_search(terms: list, context: RunnableConfig) -> dict:
    """
    è¾“å…¥æ¶ˆä¿æœ¯è¯­åˆ—è¡¨ï¼Œè¾“å‡ºæ¯ä¸ªæœ¯è¯­çš„å®šä¹‰ã€‚
    """

    print(f"\nğŸ”æ£€ç´¢å·¥å…·=æ¶ˆä¿æœ¯è¯­æŸ¥è¯¢")

    result = ""
    words = []
    with lock:
        # æ£€ç´¢å·¥å…·è°ƒç”¨ä¸­è¯†åˆ«åˆ°çš„æ¶ˆä¿æœ¯è¯­
        print("\nä»ä»»åŠ¡æŒ‡ä»¤ä¸­æ£€ç´¢æœ¯è¯­")
        for term in terms:
            if term in consumer_protection_terms:
                one_term = f"{term}ï¼š{consumer_protection_terms[term]}ã€‚"
                print(one_term)
                result += one_term
            else:
                words.append(term)
                # print(f"{term}ï¼šæœªæ‰¾åˆ°å®šä¹‰")

        # æ£€ç´¢å¾…å®¡æ ¸æ–‡æ¡£æ˜¯å¦å­˜åœ¨å…³é”®è¯
        print("\nä»æ–‡æ¡£ä¸­æ£€ç´¢æœ¯è¯­")
        document = get_runtime(context).context.get("document", "")
        if document != "":
            for term in consumer_protection_terms:
                if term in document and term not in result:
                    one_term = f"{term}ï¼š{consumer_protection_terms[term]}ã€‚"
                    print(one_term)
                    result += one_term

        # ä»LLMä¸­è·å–æœ¯è¯­å®šä¹‰
        print("\nçŸ¥è¯†åº“æœªæŸ¥åˆ°çš„æœ¯è¯­ï¼ŒLLMè‡ªå·±çš„å®šä¹‰å¦‚ä¸‹ï¼š")
        prompt = f"""
        è¯·æ ¹æ®ä½ è‡ªå·±çš„ç†è§£ï¼Œç»™å‡ºè¿™äº›æœ¯è¯­çš„å®šä¹‰ï¼Œè¾“å‡ºå½¢å¼ä¸ºï¼šæœ¯è¯­1ï¼šæœ¯è¯­1çš„å®šä¹‰ã€‚æœ¯è¯­2ï¼šæœ¯è¯­2çš„å®šä¹‰...
        æœ¯è¯­æ¸…å•ä¸ºï¼š{words}
        """
        for chunk in llm.stream(prompt):
            print(chunk.content, end="", flush=True)
            result += chunk.content

    return result
