"""
è¯„ä»·ç±»ï¼ˆåŸºäºå‡†åˆ™å’Œæ ‡å‡†ä½œå‡ºåˆ¤æ–­ï¼‰

ä¿¡æ¯æ£€æŸ¥
æ–¹æ¡ˆè¯„è®º
"""
from typing_extensions import Annotated
from langchain_core.tools import tool
from langgraph.prebuilt import InjectedState
from pydantic import BaseModel, Field
from Config.LLM_Client import llm, lock


class CheckingInput(BaseModel):
    query: str = Field(description="ä»»åŠ¡æŒ‡ä»¤")
    messages: Annotated[list, InjectedState("messages")] = Field(description="å†å²ä¸Šä¸‹æ–‡")


@tool(
    "ä¿¡æ¯æ£€æŸ¥",
    description="å½“ä»»åŠ¡éœ€è¦éªŒè¯ç»“è®º / ç»“æœæ˜¯å¦ç¬¦åˆæ—¢å®šå‡†åˆ™ã€æ•°æ®æˆ–äº‹å®ï¼ˆå¦‚æ ¸å¯¹è®¡ç®—ç»“æœå‡†ç¡®æ€§ã€æ ¡éªŒç»“è®ºä¸è¯æ®çš„åŒ¹é…åº¦ï¼‰æ—¶ï¼Œéœ€è¦é€šè¿‡æ£€æŸ¥å·¥å…·å®Œæˆä¸€è‡´æ€§éªŒè¯ã€‚",
    args_schema=CheckingInput,
)
def checking(query: str, messages: list) -> str:
    """
    æ£€æŸ¥å†å²ä¸Šä¸‹æ–‡ä¸­çš„æ‰§è¡Œè¿‡ç¨‹æ˜¯å¦ç¬¦åˆæ—¢å®šå‡†åˆ™ã€æ•°æ®æˆ–äº‹å®ã€‚
    """
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¿¡æ¯æ£€æŸ¥æ¨¡å—ï¼Œä½ çš„ä»»åŠ¡æ˜¯æ£€æŸ¥å†å²ä¸Šä¸‹æ–‡ä¸­çš„æ‰§è¡Œè¿‡ç¨‹ï¼Œæ˜¯å¦ç¬¦åˆæ—¢å®šå‡†åˆ™ã€æ•°æ®æˆ–äº‹å®ã€‚
    ä»»åŠ¡æŒ‡ä»¤æ˜¯ï¼š{query}ã€‚
    å†å²ä¸Šä¸‹æ–‡ï¼š{messages}
    è¾“å‡ºæ ¼å¼ä¸ºï¼šæ£€æŸ¥ç»“æœ
    """
    with lock:
        # æµå¼è¾“å‡º
        chunks  = []
        print(f"\nğŸ’¡è®¤çŸ¥å·¥å…·=ä¿¡æ¯æ£€æŸ¥")
        for chunk in llm.stream(prompt):
            print(chunk.content, end="", flush=True)
            chunks.append(chunk.content)

        response = "".join(chunks)

        # # å®Œæ•´è¾“å‡º
        # response = llm.invoke(prompt).content
        # print(f"\nğŸ’¡è®¤çŸ¥å·¥å…·=ä¿¡æ¯æ£€æŸ¥\n{response}")

    return response


class CritiquingInput(BaseModel):
    query: str = Field(description="ä»»åŠ¡æŒ‡ä»¤")
    messages: Annotated[list, InjectedState("messages")] = Field(description="å†å²ä¸Šä¸‹æ–‡")


@tool(
    "æ–¹æ¡ˆè¯„è®º",
    description="å½“ä»»åŠ¡éœ€è¦åŸºäºæ—¢å®šæ ‡å‡†è¯„åˆ¤æ–¹æ¡ˆ / æ–¹æ³•çš„ä¼˜åŠ£ã€å¯è¡Œæ€§æˆ–åˆç†æ€§ï¼ˆå¦‚å¯¹æ¯”è§£å†³é—®é¢˜çš„ä¸¤ç§æ€è·¯ã€è¯„ä¼°æ–¹æ¡ˆçš„è½åœ°ä»·å€¼ï¼‰æ—¶ï¼Œéœ€è¦é€šè¿‡è¯„è®ºå·¥å…·ç»™å‡ºè¯„åˆ¤ç»“è®ºä¸ä¾æ®ã€‚",
    args_schema=CritiquingInput,
)
def critiquing(query: str, messages: list) -> str:
    """
    é’ˆå¯¹ä»»åŠ¡æŒ‡ä»¤ï¼Œç»™å‡ºç›¸ä¼¼çš„ä»»åŠ¡æ ·ä¾‹ã€‚
    """
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªæ–¹æ¡ˆè¯„è®ºæ¨¡å—ï¼Œä½ éœ€è¦æ ¹æ®ä»»åŠ¡æŒ‡ä»¤ï¼Œå¯¹æ¯”ä¸Šä¸‹æ–‡å·²ç»è®¾è®¡çš„æ–¹æ¡ˆï¼Œç»™å‡ºç»™å‡ºè¯„åˆ¤ç»“è®ºä¸ä¾æ®ã€‚
    ä»»åŠ¡æŒ‡ä»¤æ˜¯ï¼š{query}ã€‚
    è¾“å‡ºæ ¼å¼ä¸ºï¼šæ–¹æ¡ˆ1æ€ä¹ˆæ ·, æ–¹æ¡ˆ2æ€ä¹ˆæ ·...
    """
    with lock:
        # æµå¼è¾“å‡º
        chunks  = []
        print(f"\nğŸ’¡è®¤çŸ¥å·¥å…·=æ–¹æ¡ˆè¯„è®º")
        for chunk in llm.stream(prompt):
            print(chunk.content, end="", flush=True)
            chunks.append(chunk.content)

        response = "".join(chunks)

        # # å®Œæ•´è¾“å‡º
        # response = llm.invoke(prompt).content
        # print(f"\nğŸ’¡è®¤çŸ¥å·¥å…·=æ–¹æ¡ˆè¯„è®º\n{response}")

    return response
