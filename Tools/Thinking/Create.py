"""
åˆ›é€ ç±»ï¼ˆå°†è¦ç´ ç»„æˆæ–°æ•´ä½“æˆ–é‡ç»„ä¸ºæ–°æ¨¡å‹ / ä½“ç³»ï¼‰

ä»»åŠ¡åˆ†è§£
"""

from typing_extensions import Annotated
from langchain_core.tools import tool
from langgraph.prebuilt import InjectedState
from langchain_core.runnables.config import RunnableConfig
from langgraph.runtime import get_runtime
from pydantic import BaseModel, Field
from Config.LLM_Client import llm, lock


class DecomposeInput(BaseModel):
    query: str = Field(description="ä»»åŠ¡æŒ‡ä»¤")
    messages: Annotated[list, InjectedState("messages")] = Field(description="å†å²ä¸Šä¸‹æ–‡")


@tool(
    "ä»»åŠ¡åˆ†è§£",
    description="å¦‚æœå½“å‰ä»»åŠ¡è¿‡äºå¤æ‚ï¼Œéœ€è¦æ‹†è§£ä¸ºè‹¥å¹²ä¸ªç›¸å¯¹ç®€å•çš„å­ä»»åŠ¡ã€‚",
    args_schema=DecomposeInput,
)
def decompose(query: str, messages: Annotated[list, InjectedState("messages")], context: RunnableConfig) -> str:
    """
    å¦‚æœå½“å‰ä»»åŠ¡è¿‡äºå¤æ‚ï¼Œéœ€è¦æ‹†è§£ä¸ºè‹¥å¹²ä¸ªç›¸å¯¹ç®€å•çš„å­ä»»åŠ¡ã€‚
    """
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡åˆ†è§£æ¨¡å—ï¼Œä½ çš„èŒè´£æ˜¯å°†å½“å‰ä»»åŠ¡æŒ‡ä»¤æ‹†è§£ä¸ºè‹¥å¹²ä¸ªç›¸å¯¹ç®€å•çš„å­ä»»åŠ¡ï¼Œæ‹†è§£çš„å­ä»»åŠ¡æ•°ä¸å®œè¶…è¿‡5ä¸ªã€‚
    æ–‡æ¡£æ˜¯ï¼š{get_runtime(context).context.get("document", "")}
    ä»»åŠ¡æŒ‡ä»¤æ˜¯ï¼š{query}ã€‚
    ä¸Šä¸‹æ–‡æ˜¯ï¼š{messages}
    è¾“å‡ºæ ¼å¼ä¸ºï¼šå­ä»»åŠ¡1, å­ä»»åŠ¡2, ...
    """
    with lock:
        # æµå¼è¾“å‡º
        chunks  = []
        print(f"\nğŸ’¡è®¤çŸ¥å·¥å…·=ä»»åŠ¡åˆ†è§£")
        for chunk in llm.stream(prompt):
            print(chunk.content, end="", flush=True)
            chunks.append(chunk.content)

        response = "".join(chunks)

        # # å®Œæ•´è¾“å‡º
        # response = llm.invoke(prompt).content
        # print(f"\nğŸ’¡è®¤çŸ¥å·¥å…·=ä»»åŠ¡åˆ†è§£\n{response}")

    return response
