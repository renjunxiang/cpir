import os, json
from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage
from langgraph.prebuilt import ToolNode
from langgraph.runtime import get_runtime
from Config.LLM_Client import llm
from Tools.Thinking import (
    recalling,
    recognizing,
    interpreting,
    exemplifying,
    direct_answer,
    decompose,
    checking,
    critiquing,
)
from Tools.Search import (
    insurance_terms_search,  # ä¿é™©æœ¯è¯­æŸ¥è¯¢
    consumer_protection_terms_search,  # æ¶ˆä¿æœ¯è¯­æŸ¥è¯¢
    rules_search,  # å®¡æ ¸è§„åˆ™æŸ¥è¯¢
)

# è½½å…¥å·¥å…·
tools = [
    recalling,  # ä¸Šä¸‹æ–‡å›å¿†
    recognizing,  # è¦ç´ è¯†åˆ«
    interpreting,  # ä»»åŠ¡è§£é‡Š
    exemplifying,  # ä»»åŠ¡ä¸¾ä¾‹
    decompose,  # ä»»åŠ¡åˆ†è§£
    checking,  # ä¿¡æ¯æ£€æŸ¥
    critiquing,  # æ–¹æ¡ˆè¯„è®º
    # direct_answer,  # ç›´æ¥ä½œç­”
    insurance_terms_search,  # ä¿é™©æœ¯è¯­æŸ¥è¯¢
    consumer_protection_terms_search,  # æ¶ˆä¿æœ¯è¯­æŸ¥è¯¢
    rules_search,  # å®¡æ ¸è§„åˆ™æŸ¥è¯¢
]
llm_with_tools = llm.bind_tools(tools)


# å›ºåŒ–ä¿¡æ¯
class ContextSchema(TypedDict):
    """
    ä¸æ›´æ”¹çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä¸Šä¼ çš„æ–‡æ¡£ä¿¡æ¯
    """

    document: str = ""


# çŠ¶æ€ä¿¡æ¯
class State(TypedDict):
    """
    ä¿æŒæ›´æ–°çš„çŠ¶æ€å®šä¹‰
    """

    messages: Annotated[list, add_messages]
    memory: list
    query: str
    query_rewrite: str
    response: str = "å¾ˆæŠ±æ­‰ï¼Œè¯¥é—®é¢˜ç›®å‰æ— æ³•å›ç­”ã€‚"
    n_tools: int
    n_loop: int = 0


# æ‹’ç­”åˆ¤æ–­
def reject(state: State):
    """
    åˆ¤æ–­æ˜¯å¦æ‹’ç»å›ç­”ï¼Œæ›´æ–°åœ¨çŠ¶æ€çš„"reject"å­—æ®µ
    1. è¿”å›â€œå›ç­”â€ï¼šç›®æ ‡æ˜ç¡®ä¸”ä¸è¿è§„
    2. è¿”å›â€œæ‹’ç­”â€ï¼šç›®æ ‡ä¸æ˜ç¡®æˆ–è¿è§„
    """
    # print(f"\n=====æˆ‘ä»¬çœ‹çœ‹è¿›å…¥åˆ°rejectçš„çŠ¶æ€æ˜¯å•¥æ ·ï¼š=====\n{state}\n")
    query = state["query"]
    messages = state["messages"]
    prompt = f"è¯·ç»¼åˆå†å²ä¸Šä¸‹æ–‡ï¼Œåˆ¤æ–­å½“å‰é—®é¢˜æ˜¯å¦å­˜åœ¨è‰²æƒ…ã€æš´åŠ›ç­‰å®‰å…¨é£é™©ï¼Œå¦‚æœä¸å­˜åœ¨å®‰å…¨é£é™©åˆ™è¿”å›â€œå›ç­”â€ï¼Œå¦åˆ™è¿”å›â€œæ‹’ç­”â€ã€‚ç”¨æˆ·å½“å‰çš„é—®é¢˜æ˜¯ï¼š{query}ã€‚å†å²ä¸Šä¸‹æ–‡ä¸ºï¼š{messages}"
    messages.append(
        {
            "role": "user",
            "content": prompt,
        }
    )

    # æµå¼è¾“å‡º
    response = ""
    for chunk in llm.stream(prompt):
        response += chunk.content

    # # ç›´æ¥è¾“å‡º
    # response = llm.invoke(messages).content
    messages.pop()  # å‰”é™¤ä¸­é—´åˆ¤æ–­ä¿¡æ¯

    # è¿‡ç¨‹è®°å½•
    state["memory"].extend(
        [
            {
                "role": "user",
                "content": query,
            },
            {
                "role": "assistant",
                "content": response,
            },
        ]
    )
    if "å›ç­”" in response:
        return "å›ç­”"
    else:
        state["response"] = "å¾ˆæŠ±æ­‰ï¼Œè¯¥é—®é¢˜ç›®å‰æ— æ³•å›ç­”ã€‚"
    return "æ‹’ç­”"


def planing(state: State) -> State:
    """
    è®¡åˆ’ä¸‹ä¸€æ­¥çš„æ“ä½œ
    """
    message = state["messages"]
    query = state["query"]
    ctx = get_runtime(ContextSchema)
    document = ctx.context.get("document", "")

    # å­˜åœ¨å®¡æ ¸æ–‡æ¡£æ˜¯å®¡æ ¸ä»»åŠ¡
    if document != "":
        prompt = f"""
        ç”¨æˆ·ä¸Šä¼ äº†ä¸€ä»½å¾…å®¡æ ¸çš„å®£ä¼ æ–‡æ¡£å†…å®¹ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡ä»»åŠ¡è§„åˆ’ã€è¡ŒåŠ¨å’Œåæ€çš„é—­ç¯æ¥å®Œæˆæ–‡æ¡£å®¡æ ¸ä»»åŠ¡ï¼Œåªéœ€è¦èšç„¦æ–‡æ¡£å°±å¯ä»¥ï¼Œä¸è¦å‘æ•£åˆ°æ–‡æ¡£å†…æåŠçš„å…¶ä»–æ–‡æ¡£ã€‚
        ä½ æ˜¯å…¶ä¸­çš„ä»»åŠ¡è§„åˆ’æ¨¡å—ï¼Œéœ€è¦æ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤å’Œä¸Šä¸‹æ–‡è½¨è¿¹ï¼Œé€šè¿‡è°ƒç”¨å„ç§è®¤çŸ¥å·¥å…·å’Œä¿¡æ¯æœç´¢å·¥å…·ï¼Œæ¥è§„åˆ’ä¸‹ä¸€æ­¥çš„è¡ŒåŠ¨ã€‚ç›¸å…³æŒ‡ç¤ºå¦‚ä¸‹ï¼š
        1.å®£ä¼ æ–‡æ¡£å†…å®¹æ˜¯ï¼š{document}ã€‚ç”¨æˆ·é—®é¢˜æ˜¯ï¼š{query}ã€‚ä¸Šä¸‹æ–‡è½¨è¿¹æ˜¯ï¼š{message}ã€‚
        2.è®¤çŸ¥å·¥å…·æ¸…å•ï¼šä¸Šä¸‹æ–‡å›å¿†ã€è¦ç´ è¯†åˆ«ã€ä»»åŠ¡è§£é‡Šã€ä»»åŠ¡ä¸¾ä¾‹ã€ä»»åŠ¡åˆ†è§£ã€ä¿¡æ¯æ£€æŸ¥ã€æ–¹æ¡ˆè¯„è®ºã€‚ä»–ä»¬æ˜¯å¸®åŠ©ä½ åœ¨å¤æ‚ä»»åŠ¡ä¸‹åšå¥½æ€è€ƒçš„ï¼Œå¦‚æœä½ è®¤ä¸ºå½“å‰ä»»åŠ¡å¾ˆç®€å•ï¼Œå¯ä»¥ä¸è°ƒç”¨è®¤çŸ¥å·¥å…·ã€‚
        3.ä¿¡æ¯æœç´¢å·¥å…·æ¸…å•ï¼šä¿é™©æœ¯è¯­æŸ¥è¯¢ã€æ¶ˆä¿æœ¯è¯­æŸ¥è¯¢ã€å®¡æ ¸è§„åˆ™æŸ¥è¯¢ã€‚ä»–ä»¬æ˜¯å¸®åŠ©ä½ è·å–é¢å¤–çš„ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯åœ¨æ–‡æ¡£å’Œç”¨æˆ·æé—®ä¸­æ²¡æœ‰ç›´æ¥ç»™å‡ºï¼Œå¦‚æœä½ è®¤ä¸ºä¸éœ€è¦é¢å¤–ä¿¡æ¯ä¹Ÿèƒ½å›ç­”ï¼Œå¯ä»¥ä¸è°ƒç”¨æœç´¢å·¥å…·ã€‚
        4.è¯·ç»™å‡ºä½ è®¤ä¸ºåç»­æ‰§è¡Œçš„è¡ŒåŠ¨æ˜¯ä»€ä¹ˆï¼Œå°†äº¤ç»™è¡ŒåŠ¨æ¨¡å—å»å…·ä½“æ‰§è¡Œï¼Œå·¥å…·ä»…å±€é™åœ¨ç›®å‰æåŠçš„è®¤çŸ¥å·¥å…·å’Œä¿¡æ¯æœç´¢å·¥å…·ã€‚
        5.åŒä¸€ä¸ªå·¥å…·ä¸èƒ½è¢«è¿ç»­è°ƒç”¨ï¼Œé™¤éä¸Šä¸€è½®æ‰§è¡Œå¤±è´¥ã€‚
        6.å¦‚æœä½ è®¤ä¸ºå½“å‰å·²ç»æ‰§è¡Œå®Œæ¯•ç”¨æˆ·çš„ä»»åŠ¡æŒ‡ä»¤ï¼Œåˆ™æ— éœ€å†è°ƒç”¨å·¥å…·ï¼Œç›´æ¥è¿”å›æœ€ç»ˆç­”æ¡ˆå³å¯ã€‚
        """
    # ä¸å­˜åœ¨å®¡æ ¸æ–‡æ¡£å°±å½“æˆé—®ç­”ä»»åŠ¡
    else:
        prompt = f"""
        ç»™å®šç”¨æˆ·çš„ä»»åŠ¡æŒ‡ä»¤ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡ä»»åŠ¡è§„åˆ’ã€è¡ŒåŠ¨å’Œåæ€é—­ç¯æ¥å®Œæˆç”¨æˆ·çš„ä»»åŠ¡ã€‚
        ä½ æ˜¯å…¶ä¸­çš„ä»»åŠ¡è§„åˆ’æ¨¡å—ï¼Œéœ€è¦æ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤å’Œä¸Šä¸‹æ–‡è½¨è¿¹ï¼Œé€šè¿‡è°ƒç”¨å„ç§è®¤çŸ¥å·¥å…·å’Œä¿¡æ¯æœç´¢å·¥å…·ï¼Œæ¥è§„åˆ’ä¸‹ä¸€æ­¥çš„è¡ŒåŠ¨ã€‚ç›¸å…³æŒ‡ç¤ºå¦‚ä¸‹ï¼š
        1.ç”¨æˆ·é—®é¢˜æ˜¯ï¼š{query}ã€‚ä¸Šä¸‹æ–‡è½¨è¿¹æ˜¯ï¼š{message}ã€‚
        2.è¯·ç»™å‡ºä½ è®¤ä¸ºåç»­æ‰§è¡Œçš„è¡ŒåŠ¨æ˜¯ä»€ä¹ˆï¼Œå°†äº¤ç»™è¡ŒåŠ¨æ¨¡å—å»å…·ä½“æ‰§è¡Œã€‚
        3.è®¤çŸ¥å·¥å…·æ¸…å•ï¼šä¸Šä¸‹æ–‡å›å¿†ã€è¦ç´ è¯†åˆ«ã€ä»»åŠ¡è§£é‡Šã€ä»»åŠ¡ä¸¾ä¾‹ã€ä»»åŠ¡åˆ†è§£ã€ä¿¡æ¯æ£€æŸ¥ã€æ–¹æ¡ˆè¯„è®ºã€‚ä»–ä»¬æ˜¯å¸®åŠ©ä½ åœ¨å¤æ‚ä»»åŠ¡ä¸‹åšå¥½æ€è€ƒçš„ï¼Œå¦‚æœä½ è®¤ä¸ºå½“å‰ä»»åŠ¡å¾ˆç®€å•ï¼Œå¯ä»¥ä¸è°ƒç”¨è®¤çŸ¥å·¥å…·ã€‚
        4.ä¿¡æ¯æœç´¢å·¥å…·æ¸…å•ï¼šä¿é™©æœ¯è¯­æŸ¥è¯¢ã€æ¶ˆä¿æœ¯è¯­æŸ¥è¯¢ã€å®¡æ ¸è§„åˆ™æŸ¥è¯¢ã€‚ä»–ä»¬æ˜¯å¸®åŠ©ä½ è·å–é¢å¤–çš„ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯ç”¨æˆ·æé—®ä¸­æ²¡æœ‰ç›´æ¥ç»™å‡ºï¼Œå¦‚æœä½ è®¤ä¸ºä¸éœ€è¦é¢å¤–ä¿¡æ¯ä¹Ÿèƒ½å›ç­”ï¼Œå¯ä»¥ä¸è°ƒç”¨æœç´¢å·¥å…·ã€‚
        5.å·¥å…·è°ƒç”¨ä¼šæ¶ˆè€—å¤§é‡æ—¶é—´ï¼Œå¦‚æœä¸€ä¸ªå·¥å…·å¤šæ¬¡æ‰§è¡Œå¤±è´¥æˆ–è€…æ•ˆæœä¸ä½³ï¼Œè¯·æ›´æ¢å·¥å…·é¿å…é™·å…¥å¾ªç¯ã€‚
        6.å¦‚æœä½ è®¤ä¸ºå½“å‰å·²ç»æ‰§è¡Œå®Œæ¯•ç”¨æˆ·çš„ä»»åŠ¡æŒ‡ä»¤ï¼Œåˆ™æ— éœ€å†è°ƒç”¨å·¥å…·ï¼Œç›´æ¥è¿”å›æœ€ç»ˆç­”æ¡ˆå³å¯ã€‚
        """

    # å¦‚æœä¸Šä¸€ä¸ªå·¥å…·è°ƒç”¨æ˜¯ç›´æ¥å›ç­”ï¼Œå°±ç»“æŸäº†ï¼Œä¸å†è§„åˆ’ã€‚
    messages = state["messages"]
    if len(messages) >= 2:
        if messages[-2].name == "ç›´æ¥ä½œç­”" and "æœ‰æ•ˆ" in messages[-1].content:
            print(f"\n\nğŸ‘ä»»åŠ¡å®Œæˆ")
            return {"response": messages[-2].content, "n_tools": 0}

    # æµå¼è¾“å‡º
    gen = llm_with_tools.stream(prompt)
    response = None
    print("\n")
    for chunk in gen:
        if response is None:
            response = chunk
        else:
            response = response + chunk

        if not response.tool_calls:
            print(chunk.content, end="", flush=True)

    # # ç›´æ¥è¾“å‡º
    # response = llm_with_tools.invoke(prompt)

    # æ ¹æ®æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨æ¥åˆ¤æ–­ä»»åŠ¡ç»“æŸ
    if response.tool_calls:
        print(f"\n\nğŸ‘‰è§„åˆ’ä¸‹ä¸€æ­¥ï¼šå·¥å…·è°ƒç”¨\n{response.tool_calls}")
        return {"messages": response, "n_tools": len(response.tool_calls)}
    else:
        print(f"\n\nğŸ‘ä»»åŠ¡å®Œæˆ")
        return {"messages": response, "response": response.content, "n_tools": 0}


def should_use_tool(state: State) -> str:
    n_tools = state["n_tools"]
    if n_tools > 0:
        return "tools"
    else:
        return END


def verify_tool_call(state: State) -> State:
    """
    éªŒè¯å·¥å…·è°ƒç”¨æ˜¯å¦æ­£ç¡®
    """
    query = state["query"]
    n_tools = state["n_tools"]
    message = state["messages"]
    for tool_response in message[-n_tools:]:
        state["memory"].append(tool_response)

    demo = {
        "å·¥å…·è°ƒç”¨": ["ä¸Šä¸‹æ–‡å›å¿†"],
        "ç»“è®º": "æœ‰æ•ˆæˆ–æ— æ•ˆ",
        "åæ€": "æ­£ç¡®æ‰§è¡Œäº†è§„åˆ’æ¨¡å—çš„è¡ŒåŠ¨è¦æ±‚ï¼›ä½†ä»»åŠ¡å°šæœªå®Œæˆï¼Œä»éœ€åç»­çš„ä¿¡æ¯è·å–åŠ¨ä½œæ¥çœŸæ­£æ»¡è¶³ç”¨æˆ·æŸ¥è¯¢éœ€æ±‚ã€‚",
    }
    prompt = f"""
    ç»™å®šç”¨æˆ·çš„æŒ‡ä»¤ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡ä»»åŠ¡è§„åˆ’ã€è¡ŒåŠ¨å’Œåæ€é—­ç¯æ¥å®Œæˆç”¨æˆ·çš„ä»»åŠ¡ã€‚ã€‚
    ä½ æ˜¯å…¶ä¸­çš„éªŒè¯åæ€æ¨¡å—ï¼Œéœ€è¦åˆ¤æ–­å·¥å…·çš„æ‰§è¡Œç»“æœæ˜¯å¦æœ‰æ•ˆæ¨è¿›äº†ä»»åŠ¡è§£ç­”ã€‚ç›¸å…³æŒ‡ç¤ºå¦‚ä¸‹ï¼š
    1. å½“å‰çš„ç”¨æˆ·é—®é¢˜æ˜¯ï¼š{query}ã€‚å†å²æ‰§è¡Œè½¨è¿¹æ˜¯ï¼š{message[:-n_tools]}ã€‚è¡ŒåŠ¨ç»“æœä¸ºï¼š{message[-n_tools :]}ã€‚
    2. è¯·ç»™å‡ºä½ å¯¹å·¥å…·è°ƒç”¨ç»“æœçš„åˆ†æï¼Œåˆ¤æ–­æ˜¯å¦æ»¡è¶³è§„åˆ’æ¨¡å—çš„ç¬¦åˆé¢„æœŸï¼Œè¿”å›çš„å‚è€ƒæ ·ä¾‹ä¸º{demo}ï¼Œè¯·ä¿æŒè¾“å‡ºçš„ç²¾ç‚¼ç®€æ´ã€‚
    """
    # æµå¼è¾“å‡º
    chunks = []
    print(f"\n\nğŸ‘€éªŒè¯åæ€ç»“æœ")
    for chunk in llm.stream(prompt):
        print(chunk.content, end="", flush=True)
        chunks.append(chunk.content)

    response = "".join(chunks)
    state["memory"].append({"verify_tool_call": response})

    # # å®Œæ•´è¾“å‡º
    # response = llm.invoke(prompt)
    # state["memory"].append({"verify_tool_call": response.content})
    # print(f"\nğŸ‘‰éªŒè¯åæ€ç»“æœ\n{response.content}")

    return {"messages": AIMessage(content=response), "n_loop": state["n_loop"] + 1}


def break_loop(state: State) -> State:
    """
    éªŒè¯æ¬¡æ•°è¶…å‡ºæœ€å¤§æ¬¡æ•°æ—¶ï¼Œè·³å‡ºå¾ªç¯
    """
    if state["n_loop"] >= 100:
        return END
    else:
        return "continue"


graph = StateGraph(State)
graph.add_node("è§„åˆ’", planing)
tool_node = ToolNode(tools=tools)
graph.add_node("å·¥å…·è°ƒç”¨", tool_node)
graph.add_node("è¡ŒåŠ¨éªŒè¯", verify_tool_call)


graph.add_conditional_edges(START, reject, {"æ‹’ç­”": END, "å›ç­”": "è§„åˆ’"})
graph.add_conditional_edges("è§„åˆ’", should_use_tool, {"tools": "å·¥å…·è°ƒç”¨", END: END})
graph.add_edge("å·¥å…·è°ƒç”¨", "è¡ŒåŠ¨éªŒè¯")
graph.add_conditional_edges("è¡ŒåŠ¨éªŒè¯", break_loop, {"continue": "è§„åˆ’", END: END})
# ç¼–è¯‘é™æ€å›¾
app = graph.compile()

# # ç²—ç•¥å¯è§†åŒ–
# app.get_graph().print_ascii()

# # ä¿å­˜é™æ€å›¾
# if not os.path.exists("./output"):
#     os.makedirs("./output")
# png_data = app.get_graph(xray=True).draw_mermaid_png()
# with open("./output/graph.png", "wb") as f:
#     f.write(png_data)

if __name__ == "__main__":
    """
    æ–‡æ¡ˆå‚è€ƒ
    åˆ†çº¢é™©ï¼šå®¶åº­è´¢å¯Œçš„æœ€ä¼˜ä¿éšœé€‰æ‹©\n\næ—¢è¦ç¨³ç¨³çš„æ”¶ç›Šï¼Œåˆè¦æ»¡æ»¡çš„å®‰å¿ƒï¼Ÿå‘±å‘±åˆ†çº¢é™©å¿…é€‰ï¼æ¯”å­˜æ¬¾åˆ©æ¯é«˜ã€æ¯”åŸºé‡‘æ›´é è°±ï¼Œä¸‹æœ‰ 3% ä¿è¯æ”¶ç›Šæ‰˜åº•ï¼Œä¸Šæœ‰å¹´å¹´åˆ†çº¢ç¨³èµšè¶…é¢æ”¶ç›Šï¼Œç»æµå†æ³¢åŠ¨ä¹Ÿèƒ½èººèµ¢ï¼ä¸ç®¡æ˜¯å…»è€è§„åˆ’è¿˜æ˜¯å­å¥³æ•™è‚²ï¼Œéƒ½æ˜¯ä¸äºŒä¹‹é€‰ï½

    æŒ‡ä»¤å‚è€ƒ
    ç™¾ä¸‡åŒ»ç–—é™©çš„ä¿è¯ç»­ä¿æªè¾æœ‰ä»€ä¹ˆè¦æ³¨æ„çš„ï¼Ÿ
    è¯·å¸®æˆ‘æŒ‡å‡ºæ–‡æ¡£ä¸­å“ªäº›å†…å®¹è¿åæ¶ˆä¿åˆè§„é—®é¢˜ï¼Œåˆ†åˆ«è¿åäº†ä»€ä¹ˆè§„å®šï¼Ÿ
    """

    state = {
        "query": "",
        "messages": [],
        "memory": [],
        "n_tools": 0,
        "n_loop": 0,
        "response": "å›ç­”å®Œæ¯•",
    }

    print("\nğŸ¤– æœºå™¨äººï¼šä½ å¥½å‘€ï¼")
    while True:
        # è·å–ç”¨æˆ·æ–‡æ¡£
        document = input("\nğŸ“ è¯·è¾“å…¥å¾…å®¡æ ¸æ–‡æ¡£ï¼ˆå¦‚æœæ²¡æœ‰è¯·ç›´æ¥å›è½¦ï¼‰: ")
        context = {
            "document": document,
        }
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = input("\nğŸ‘¤ ä½ : ")

        # å¦‚æœè¾“å…¥ exit å°±ç»“æŸ
        if user_input.lower() == "exit":
            print("\nğŸ¤– æœºå™¨äºº: å†è§ï¼")
            break
        else:
            user_input = user_input

        # æ›´æ–°agentçŠ¶æ€ï¼Œæ›¿æ¢ä¸ºæœ¬è½®ç”¨æˆ·æŸ¥è¯¢
        state["query"] = user_input
        state["response"] = ""
        # print(state)
        state = app.invoke(
            state,
            context=context,
            config={"recursion_limit": 100},  # å› ä¸ºè¿™é‡Œå¤šæ­¥æ€è€ƒå¯èƒ½ä¼šå¾ˆå¤šè½®
        )
        response = state["response"]
        print(f"\nğŸ¤– æœºå™¨äººï¼š{response}")
